{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pyspark in c:\\users\\ajl0618\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\ajl0618\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\ajl0618\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PBPPlanBuilder\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system parameters\\\n",
    "PBP_SOURCE_FOLDER = 'PBP_Benefits_2025/'\n",
    "DR_TARGET_FOLDER = 'PBP_Benefits_2025_Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year parameter for CMS\n",
    "\n",
    "PLAN_YEAR = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all required files\n",
    "def load_csv(csv_file_path):\n",
    "    return spark.read.format(\"csv\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(csv_file_path)\n",
    "\n",
    "# drop views from memory if the view exist\n",
    "for t in spark.catalog.listTables():\n",
    "    spark.catalog.dropTempView(t.name)\n",
    "\n",
    "df_pbp_section_A = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_A.txt')\n",
    "df_pbp_section_A.createTempView('pbp_section_A')\n",
    "\n",
    "df_pbp_mrx_tier = load_csv(PBP_SOURCE_FOLDER + 'pbp_mrx_tier.txt')\n",
    "df_pbp_mrx_tier.createTempView('pbp_mrx_tier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of utility functions\n",
    "def write_to_csv_file(df, file_name):\n",
    "    pandas_df = df.toPandas()\n",
    "    pandas_df.to_csv(DR_TARGET_FOLDER + file_name + '.csv', index=False)\n",
    "\n",
    "def read_pd_from_csv_file(file_name):\n",
    "    return pd.read_csv(DR_TARGET_FOLDER + file_name + '.csv')\n",
    "\n",
    "def write_pd_to_csv(df, file_name):\n",
    "    df.to_csv(DR_TARGET_FOLDER + file_name + '.csv', index=False)\n",
    "\n",
    "def convert_to_int(field, null_value):\n",
    "    if field is None:\n",
    "        return null_value\n",
    "    return int(field)\n",
    "\n",
    "def convert_to_currency(float_field):\n",
    "    return '${:,.2f}'.format(float_field)\n",
    "\n",
    "def convert_to_currency_no_decimal(float_field):\n",
    "    return '${:,.0f}'.format(float_field)\n",
    "\n",
    "def drop_pbp_mrx_columns(df):\n",
    "\tpbp_mrx_columns = []\n",
    "\tfor column_name in df.columns:\n",
    "\t\tif column_name.lower().startswith('pbp_') or column_name.lower().startswith('mrx_'):\n",
    "\t\t\tpbp_mrx_columns.append(column_name)\n",
    "\tdf = df.drop(pbp_mrx_columns, axis=1)\n",
    "\treturn df\n",
    "\n",
    "def drop_pbp_mrx_columns(df):\n",
    "\tpbp_mrx_columns = []\n",
    "\tfor column_name in df.columns:\n",
    "\t\tif column_name.lower().startswith('pbp_') or column_name.lower().startswith('mrx_'):\n",
    "\t\t\tpbp_mrx_columns.append(column_name)\n",
    "\tdf = df.drop(pbp_mrx_columns, axis=1)\n",
    "\treturn df\n",
    "\n",
    "def get_medicare_site_url(qid):\n",
    "    contractid = qid[:5]\n",
    "    planid = qid[5:8]\n",
    "    segmentid = qid[8:]\n",
    "    return f'https://www.medicare.gov/plan-compare/#/plan-details/{PLAN_YEAR}-{contractid}-{planid}-{int(segmentid)}?year={PLAN_YEAR}&lang=en#benefits'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select \n",
    "    a.pbp_a_hnumber as ContractID,\t\n",
    "\ta.pbp_a_plan_identifier as PlanID, \t\n",
    "\ta.segment_id as SegmentID, \n",
    "    10 as COVERAGE_LEVEL,\n",
    "    30 as DAYS_SUPPLY,\n",
    "    mrx_tier_id as TIER,\n",
    "    mrx_tier_label_list as TIER_DESC,\n",
    "    mrx_tier_rstd_copay_1m, \n",
    "    mrx_tier_rstd_coins_1m,\n",
    "    mrx_tier_rsstd_copay_1m,\n",
    "    mrx_tier_rsstd_coins_1m,\n",
    "    mrx_tier_rspfd_copay_1m,\n",
    "    mrx_tier_rspfd_coins_1m\n",
    "    \n",
    "\tfrom pbp_mrx_tier m \n",
    "\tinner join pbp_Section_A a on m.bid_id = a.bid_id\n",
    "where CAST(a.pbp_a_plan_identifier AS INT) < 800 and cast(pbp_a_eghp_yn as int) = 2  \n",
    "'''\n",
    "\n",
    "df_rx_tier_benefits = spark.sql(query)\n",
    "write_to_csv_file(df_rx_tier_benefits, 'RxTierBenefits_DataSource')\n",
    "df_rx_tier_benefits = read_pd_from_csv_file('RxTierBenefits_DataSource')\n",
    "df_rx_tier_benefits['PlanYear'] = PLAN_YEAR\n",
    "    \n",
    "from PBP_2025_Benefit_Text import  Plan # Logic implemented in Benefit Module\n",
    "\n",
    "def get_pref_cost_type(x):\n",
    "    if not pd.isna(x.mrx_tier_rspfd_copay_1m):\n",
    "        return 10\n",
    "    if not pd.isna( x.mrx_tier_rspfd_coins_1m):\n",
    "        return 20\n",
    "    return 0\n",
    "\n",
    "def get_pref_copay_amt(x):\n",
    "    if not pd.isna(x.mrx_tier_rspfd_copay_1m):\n",
    "        return x.mrx_tier_rspfd_copay_1m\n",
    "    if not pd.isna( x.mrx_tier_rspfd_coins_1m):\n",
    "        return  x.mrx_tier_rspfd_coins_1m / 100\n",
    "    return 0\n",
    "\n",
    "def get_std_cost_type(x):\n",
    "    if not pd.isna(x.mrx_tier_rstd_copay_1m) or not pd.isna(x.mrx_tier_rsstd_copay_1m):\n",
    "        return 10\n",
    "    if not pd.isna( x.mrx_tier_rstd_coins_1m) or not pd.isna(x.mrx_tier_rsstd_coins_1m):\n",
    "        return 20\n",
    "    return 0\n",
    "\n",
    "def get_std_copay_amt(x):\n",
    "    if not pd.isna(x.mrx_tier_rstd_copay_1m):\n",
    "        return x.mrx_tier_rstd_copay_1m\n",
    "    if not pd.isna(x.mrx_tier_rsstd_copay_1m):\n",
    "        return x.mrx_tier_rsstd_copay_1m\n",
    "    if not pd.isna( x.mrx_tier_rstd_coins_1m):\n",
    "        return  x.mrx_tier_rstd_coins_1m / 100\n",
    "    if not pd.isna( x.mrx_tier_rsstd_coins_1m):\n",
    "        return  x.mrx_tier_rsstd_coins_1m / 100\n",
    "    return 0\n",
    "\n",
    "df_rx_tier_benefits['QID'] = df_rx_tier_benefits.apply(lambda x:Plan.get_QID(x), axis=1)\n",
    "\n",
    "df_rx_tier_benefits['COST_TYPE_PreferredRetail'] = df_rx_tier_benefits.apply(lambda x: get_pref_cost_type(x), axis=1)\n",
    "df_rx_tier_benefits['COST_AMT_PreferredRetail'] = df_rx_tier_benefits.apply(lambda x: get_pref_copay_amt(x), axis=1)\n",
    "df_rx_tier_benefits['COST_TYPE_Retail'] = df_rx_tier_benefits.apply(lambda x: get_std_cost_type(x), axis=1)\n",
    "df_rx_tier_benefits['COST_AMT_Retail'] = df_rx_tier_benefits.apply(lambda x: get_std_copay_amt(x), axis=1)\n",
    "df_rx_tier_benefits = drop_pbp_mrx_columns(df_rx_tier_benefits)\n",
    "write_pd_to_csv(df_rx_tier_benefits, 'RxTierBenefits')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
