{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\ajl0618\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\ajl0618\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\ajl0618\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PBPPlanBuilder\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system parameters\\\n",
    "PBP_SOURCE_FOLDER = 'PBP_Benefits_2025/'\n",
    "DR_TARGET_FOLDER = 'PBP_Benefits_2025_Results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year parameter for CMS\n",
    "\n",
    "PLAN_YEAR = 2025\n",
    "RX_CATASTROHPIC_LIMIT = 2000\n",
    "RX_INITIAL_COVERAGE_LIMIT = ''\n",
    "DEDAULT_RX_DEDUCTIBLE = 545\n",
    "MEDICARE_DEDUCTIBLE_PART_A = 1632\n",
    "MEDICARE_DEDUCTIBLE_PART_B = 240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all required files\n",
    "def load_csv(csv_file_path):\n",
    "    return spark.read.format(\"csv\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(csv_file_path)\n",
    "\n",
    "# drop views from memory if the view exist\n",
    "for t in spark.catalog.listTables():\n",
    "    spark.catalog.dropTempView(t.name)\n",
    "\n",
    "df_pbp_section_A = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_A.txt')\n",
    "\n",
    "df_pbp_section_A.createTempView('pbp_section_A')\n",
    "\n",
    "df_pbp_mrx = load_csv(PBP_SOURCE_FOLDER + 'pbp_mrx.txt')\n",
    "df_pbp_mrx.createTempView('pbp_mrx')\n",
    "\n",
    "df_pbp_Section_C = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_C.txt')\n",
    "df_pbp_Section_C.createTempView('pbp_Section_C')\n",
    "\n",
    "df_pbp_Section_C_OON = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_C_OON.txt')\n",
    "df_pbp_Section_C_OON.createTempView('pbp_Section_C_OON')\n",
    "\n",
    "df_pbp_Section_C_POS = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_C_POS.txt')\n",
    "df_pbp_Section_C_POS.createTempView('pbp_Section_C_POS')\n",
    "\n",
    "df_pbp_Section_D = load_csv(PBP_SOURCE_FOLDER + 'pbp_Section_D.txt')\n",
    "df_pbp_Section_D.createTempView('pbp_Section_D')\n",
    "\n",
    "df_pbp_b1a_inpat_hosp = load_csv(PBP_SOURCE_FOLDER + 'pbp_b1a_inpat_hosp.txt')\n",
    "df_pbp_b1a_inpat_hosp.createTempView('pbp_b1a_inpat_hosp')\n",
    "\n",
    "\n",
    "df_pbp_b2_snf = load_csv(PBP_SOURCE_FOLDER + 'pbp_b2_snf.txt')\n",
    "df_pbp_b2_snf.createTempView('pbp_b2_snf')\n",
    "\n",
    "df_pbp_step2 = load_csv(PBP_SOURCE_FOLDER + 'pbp_step2.txt')\n",
    "df_pbp_step2.createTempView('pbp_step2')\n",
    "\n",
    "\n",
    "df_pbp_b4_emerg_urgent =load_csv(PBP_SOURCE_FOLDER + 'pbp_b4_emerg_urgent.txt')\n",
    "df_pbp_b4_emerg_urgent.createTempView('pbp_b4_emerg_urgent')\n",
    "\n",
    "\n",
    "df_pbp_b7_health_prof = load_csv(PBP_SOURCE_FOLDER + 'pbp_b7_health_prof.txt')\n",
    "df_pbp_b7_health_prof.createTempView('pbp_b7_health_prof')\n",
    "\n",
    "df_pbp_b8_clin_diag_ther =load_csv(PBP_SOURCE_FOLDER + 'pbp_b8_clin_diag_ther.txt')\n",
    "df_pbp_b8_clin_diag_ther.createTempView('pbp_b8_clin_diag_ther')\n",
    "\n",
    "df_pbp_b9_outpat_hosp = load_csv(PBP_SOURCE_FOLDER + 'pbp_b9_outpat_hosp.txt')\n",
    "df_pbp_b9_outpat_hosp.createTempView('pbp_b9_outpat_hosp')\n",
    "\n",
    "df_pbp_b10_amb_trans =load_csv(PBP_SOURCE_FOLDER + 'pbp_b10_amb_trans.txt')\n",
    "df_pbp_b10_amb_trans.createTempView('pbp_b10_amb_trans')\n",
    "\n",
    "df_pbp_b11_dme_prosth_orth_sup =load_csv(PBP_SOURCE_FOLDER + 'pbp_b11_dme_prosth_orth_sup.txt')\n",
    "df_pbp_b11_dme_prosth_orth_sup.createTempView('pbp_b11_dme_prosth_orth_sup')\n",
    "\n",
    "df_pbp_b13_other_services =load_csv(PBP_SOURCE_FOLDER + 'pbp_b13_other_services.txt')\n",
    "df_pbp_b13_other_services.createTempView('pbp_b13_other_services')\n",
    "\n",
    "df_pbp_b13_b19b_other_services_vbid_uf =load_csv(PBP_SOURCE_FOLDER + 'pbp_b13_b19b_other_services_vbid_uf.txt')\n",
    "df_pbp_b13_b19b_other_services_vbid_uf.createTempView('pbp_b13_b19b_other_services_vbid_uf')\n",
    "\n",
    "df_pbp_b14_preventive =load_csv(PBP_SOURCE_FOLDER + 'pbp_b14_preventive.txt')\n",
    "df_pbp_b14_preventive.createTempView('pbp_b14_preventive')\n",
    "\n",
    "df_pbp_b15_partb_rx_drugs= load_csv(PBP_SOURCE_FOLDER + 'pbp_b15_partb_rx_drugs.txt')\n",
    "df_pbp_b15_partb_rx_drugs.createTempView('pbp_b15_partb_rx_drugs')\n",
    "\n",
    "df_pbp_b16_dental= load_csv(PBP_SOURCE_FOLDER + 'pbp_b16_dental.txt')\n",
    "df_pbp_b16_dental.createTempView('pbp_b16_dental')\n",
    "\n",
    "df_pbp_b17_eye_exams_wear_aids =load_csv(PBP_SOURCE_FOLDER + 'pbp_b17_eye_exams_wear.txt')\n",
    "df_pbp_b17_eye_exams_wear_aids.createTempView('pbp_b17_eye_exams_wear')\n",
    "\n",
    "df_pbp_b18_hearing_exams_aids =load_csv(PBP_SOURCE_FOLDER + 'pbp_b18_hearing_exams_aids.txt')\n",
    "df_pbp_b18_hearing_exams_aids.createTempView('pbp_b18_hearing_exams_aids')\n",
    "\n",
    "df_pbp_b18_b19b_hearing_exams_aids_vbid_uf =load_csv(PBP_SOURCE_FOLDER + 'pbp_b18_b19b_hearing_exams_aids_vbid_uf.txt')\n",
    "df_pbp_b18_b19b_hearing_exams_aids_vbid_uf.createTempView('pbp_b18_b19b_hearing_exams_aids_vbid_uf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of utility functions\n",
    "def write_to_csv_file(df, file_name):\n",
    "    pandas_df = df.toPandas()\n",
    "    pandas_df.to_csv(DR_TARGET_FOLDER + file_name + '.csv', index=False)\n",
    "\n",
    "def read_pd_from_csv_file(file_name):\n",
    "    return pd.read_csv(DR_TARGET_FOLDER + file_name + '.csv')\n",
    "\n",
    "def write_pd_to_csv(df, file_name):\n",
    "    df.to_csv(DR_TARGET_FOLDER + file_name + '.csv', index=False)\n",
    "\n",
    "def convert_to_int(field, null_value):\n",
    "    if field is None:\n",
    "        return null_value\n",
    "    return int(field)\n",
    "\n",
    "def convert_to_currency(float_field):\n",
    "    return '${:,.2f}'.format(float_field)\n",
    "\n",
    "def convert_to_currency_no_decimal(float_field):\n",
    "    return '${:,.0f}'.format(float_field)\n",
    "\n",
    "def drop_pbp_mrx_columns(df):\n",
    "\tpbp_mrx_columns = []\n",
    "\tfor column_name in df.columns:\n",
    "\t\tif column_name.lower().startswith('pbp_') or column_name.lower().startswith('mrx_'):\n",
    "\t\t\tpbp_mrx_columns.append(column_name)\n",
    "\tdf = df.drop(pbp_mrx_columns, axis=1)\n",
    "\treturn df\n",
    "\n",
    "def drop_pbp_mrx_columns(df):\n",
    "\tpbp_mrx_columns = []\n",
    "\tfor column_name in df.columns:\n",
    "\t\tif column_name.lower().startswith('pbp_') or column_name.lower().startswith('mrx_'):\n",
    "\t\t\tpbp_mrx_columns.append(column_name)\n",
    "\tdf = df.drop(pbp_mrx_columns, axis=1)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrier, Organization, Plans\n",
    "# Source: HPMS..[usp_loadCarriersPUF] \n",
    "def get_plan_type(pbp_a_eghp_yn, pbp_a_org_type, pbp_a_plan_type, mrx_benefit_type):\n",
    "\t'''\n",
    "\tSource: HPSM..usp_loadCarriersPUF_2023\n",
    "\t'''\n",
    "\tpbp_a_eghp_yn = int(pbp_a_eghp_yn)\n",
    "\tpbp_a_org_type = int(pbp_a_org_type)\n",
    "\tpbp_a_plan_type = int(pbp_a_plan_type)\n",
    "\tif mrx_benefit_type in [1,2,3,4]:\n",
    "\t\tmrx_drug_ben_yn = 1\n",
    "\tif pbp_a_org_type == 10 and pbp_a_plan_type == 29 and mrx_drug_ben_yn == 1:\n",
    "\t\treturn 'PDP'\n",
    "\telif mrx_benefit_type == 1:\n",
    "\t\treturn 'MAPD'\n",
    "\treturn 'MA'\n",
    "\n",
    "def get_snp_type(pbp_a_special_need_flag, pbp_a_special_need_plan_type):\n",
    "\tpbp_a_special_need_flag = int(pbp_a_special_need_flag)\n",
    "\tif pbp_a_special_need_flag == 1:\n",
    "\t\tpbp_a_special_need_plan_type = int(pbp_a_special_need_plan_type)\n",
    "\t\tif pbp_a_special_need_plan_type == 1: #\tInstitutional\n",
    "\t\t\treturn 'I-SNP'\n",
    "\t\tif pbp_a_special_need_plan_type == 3: #\tDual-Eligible\n",
    "\t\t\treturn 'D-SNP'\n",
    "\t\tif pbp_a_special_need_plan_type == 4: #\tChronic or Disabling Condition\n",
    "\t\t\treturn 'C-SNP'\n",
    "\treturn ''\n",
    "\n",
    "def get_qid(ContractID, PlanID, SegmentID):\n",
    "\treturn ContractID + ('000' + str(PlanID))[-3:] + ('000' + str(SegmentID))[-3:]\n",
    "\n",
    "def get_qid_from_bid_id(bid_id):\n",
    "\tbid_id_splited = bid_id.split('_')\n",
    "\tbid_id_splited[1] = ('00' + bid_id_splited[1])[-3:]\n",
    "\tbid_id_splited[2] = ('00' + bid_id_splited[2])[-3:]\n",
    "\treturn ''.join(bid_id_splited)\n",
    "\n",
    "def get_medical_plan_type_code(pbp_a_plan_type):\n",
    "\t'''\n",
    "\tSource: hpms.dbo.f_getMedicalPlanTypeCode\n",
    "\t'''\n",
    "\tif pbp_a_plan_type is not None:\n",
    "\t\tpbp_a_plan_type = int(pbp_a_plan_type)\n",
    "\t\tif pbp_a_plan_type == 1:return 10 # 'HMO'\n",
    "\t\tif pbp_a_plan_type == 2: return 120 #'HMOPOS'\n",
    "\t\tif pbp_a_plan_type == 4: return 140 #'Local PPO'\n",
    "\t\tif pbp_a_plan_type == 5: return 230 #'PSO (State License)'#??\n",
    "\t\tif pbp_a_plan_type == 7: return 110 #'MSA'#??\n",
    "\t\tif pbp_a_plan_type == 8: return 240 #'RFB PFFS'#??\n",
    "\t\tif pbp_a_plan_type == 9: return 220 #'PFFS'\n",
    "\t\tif pbp_a_plan_type == 18: return 80 #'1876 Cost'#?? cost plan?\n",
    "\t\tif pbp_a_plan_type == 19: return 80 #'HCPP - 1833 Cost'#?? cost plan?\n",
    "\t\tif pbp_a_plan_type == 20: return 90 #'National Pace'#??\n",
    "\t\tif pbp_a_plan_type == 29: return 190 #'Medicare Prescription Drug Plan' # PDP\n",
    "\t\tif pbp_a_plan_type == 30: return 190# 'Employer/Union Only Direct Contract PDP' # PDP\n",
    "\t\tif pbp_a_plan_type == 31: return 130 #'Regional PPO' # RPPO\n",
    "\t\tif pbp_a_plan_type == 32: return 250 #'Fallback'#??\n",
    "\t\tif pbp_a_plan_type == 40: return 70 #'Employer/Union Only Direct Contract PFFS'# PFFS\n",
    "\t\tif pbp_a_plan_type == 42: return 260 #'RFB HMO'\n",
    "\t\tif pbp_a_plan_type == 43: return 270 #'RFB HMOPOS'\n",
    "\t\tif pbp_a_plan_type == 44: return 280 #'RFB Local PPO'\n",
    "\t\tif pbp_a_plan_type == 45: return 290 #'RFB PSO (State License)'\n",
    "\t\tif pbp_a_plan_type == 47: return 300 #'Employer Direct PPO'\n",
    "\t\tif pbp_a_plan_type == 48: return 100 #'MMP HMO'\n",
    "\t\tif pbp_a_plan_type == 49: return 100 #'MMP HMOPOS'\n",
    "\treturn 0 #'unknown'\n",
    "\n",
    "def get_rx_deductible_limit(mrx_alt_ded_amount, mrx_alt_ded_charge):\n",
    "\tif not np.isnan(mrx_alt_ded_amount):\n",
    "\t\treturn mrx_alt_ded_amount\n",
    "\tif not np.isnan(mrx_alt_ded_charge):\n",
    "\t\tif int(mrx_alt_ded_charge) == 1:\n",
    "\t\t\treturn float(DEDAULT_RX_DEDUCTIBLE)\n",
    "\treturn float(0)\n",
    "\n",
    "query = f'''\n",
    "SELECT \n",
    "\t{PLAN_YEAR} as PlanYear,    \n",
    "\tPBP_A_ORG_MARKETING_NAME as CarrierName, pbp_a_org_name as OrganizationName, PBP_A_ORG_WEBSITE as WebSiteAddress,\n",
    "\ta.pbp_a_hnumber as ContractID,\t\n",
    "\ta.pbp_a_plan_identifier as PlanID, \t\n",
    "\ta.segment_id as SegmentID, \n",
    "\tPBP_A_PLAN_NAME as PlanName, \n",
    "\tPBP_A_PLAN_GEOG_NAME as GeoName, \n",
    "\tm.PBP_A_PLAN_TYPE as MedicalPlanType,\n",
    "\tPBP_D_MPLUSC_PREMIUM as HealthPlanPremium, \n",
    "\tpbp_d_mco_pay_reduct_amt as PartBPremiumReduction,\n",
    "\tpbp_a_phys_web_addr as PhysicianSearchURL, \n",
    " \tpbp_a_curmbr_phone as MemberPhoneNumber, \n",
    "\tpbp_a_prombr_phone as NonMemberPhoneNumber,\n",
    "\tpbp_a_ttytdd_curmbr_phone as TTYTDDPhoneNumber,\n",
    "\tpbp_a_eghp_yn, pbp_a_org_type, pbp_a_snp_pct, pbp_a_snp_cond, m.pbp_a_plan_type,\n",
    "\tpbp_a_special_need_flag, pbp_a_special_need_plan_type, \n",
    "\tmrx_alt_ded_amount, mrx_alt_ded_charge, mrx_benefit_type\n",
    "FROM pbp_section_A a \n",
    "\tleft join pbp_mrx m on a.bid_id = m.bid_id\n",
    "\tleft join pbp_Section_D d on a.bid_id = d.bid_id\n",
    "\twhere cast(pbp_a_eghp_yn as int) = 2 and cast(m.PBP_A_PLAN_TYPE as int) in (1, 2, 4, 9, 29, 31, 42, 43, 44, 45 )\n",
    "\tand CAST(a.pbp_a_plan_identifier as INT) < 800\n",
    "'''\n",
    "\n",
    "df_plans = spark.sql(query)\n",
    "write_to_csv_file(df_plans, 'Plans')\n",
    "\n",
    "#Add calculated columns\n",
    "\n",
    "from PBP_2025_Benefit_Text import  Plan # Logic implemented in Benefit Module\n",
    "\n",
    "df_plans = read_pd_from_csv_file('Plans')\n",
    "df_plans['PlanType'] = df_plans.apply(lambda x: Plan.get_PlanType(x), axis=1)\n",
    "df_plans['SNPType'] =  df_plans.apply(lambda x: Plan.get_SNPType(x), axis=1)\n",
    "df_plans['QID'] = df_plans.apply(lambda x: Plan.get_QID(x), axis=1)\n",
    "df_plans['DrugDeductibleLimit'] = df_plans.apply(lambda x: Plan.get_DrugDeductibleLimit(x), axis=1)\n",
    "df_plans['MedicalPlanType'] = df_plans['MedicalPlanType'].apply(lambda x: get_medical_plan_type_code(x))\n",
    "df_plans = drop_pbp_mrx_columns(df_plans)\n",
    "\n",
    "write_pd_to_csv(df_plans, 'Plans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Matching DF for DR..MedicalBenefits\n",
    "'''\n",
    "pandas_df_medicalbenefits = pd.DataFrame(columns = ['QID', 'PlanYear', 'CategoryName', 'ServiceName', 'Network', 'CostShare'])\n",
    "\n",
    "\n",
    "# add to pandas_df_medicalbenefits if there is no mismatching\n",
    "def add_category_benefit_to_df_medicalbenefits(df, df_all):\n",
    "    df_new_category_service_network = df[['CategoryName', 'ServiceName', 'Network']].drop_duplicates()\n",
    "    for index, csn in df_new_category_service_network.iterrows():\n",
    "        category_name = csn['CategoryName']\n",
    "        service_name = csn['ServiceName']\n",
    "        network = csn['Network']\n",
    "        df_existing = df_all[(df_all['CategoryName'] == category_name) &  (df_all['CategoryName'] == category_name)& (df_all['Network'] == network)]\n",
    "        if len(df_existing) > 0:\n",
    "            df_all.drop(df_all.index, inplace=True)\n",
    "    df_selected = df[df_all.columns.tolist()]\n",
    "    df_all = pd.concat([df_all, df_selected], ignore_index=True)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "MEDICARE_CRAWLED_DATA = 'MedicalBenefits'\n",
    "medicare_crawled_data_file_path = f'{DR_TARGET_FOLDER}{MEDICARE_CRAWLED_DATA}.csv'\n",
    "# df_medicare_displaying_benefits = read_pd_from_csv_file(MEDICARE_CRAWLED_DATA)\n",
    "\n",
    "#utility method to compare\n",
    "def purify_cost_share(benefit):\n",
    "  if benefit is not None:\n",
    "    benefit = benefit.strip().lower().replace('not covered','not applicable')\n",
    "    benefit = benefit.strip().lower().replace(' or ', ', ').replace('<br/>', '').replace('<br />', '').replace('\\r','')\n",
    "    benefit = benefit.strip().lower().replace('(limits apply)','').replace('(always covered)','')\n",
    "    benefit = benefit.replace(' per item', '').replace('(always covered)','')\n",
    "    benefit = re.sub('maximum \\d+ (other|(every (year|\\d? years)))', '', benefit)\n",
    "    if benefit.strip() == f\"$0 copay, 0% coinsurance\":\n",
    "      benefit = '$0 copay'\n",
    "    if benefit.strip() == f'0% coinsurance':\n",
    "      benefit = '$0 copay'\n",
    "  return benefit\n",
    "#utility method to compare\n",
    "def matched(benefit1, benefit2):\n",
    "  if benefit1 is not None and benefit2 is not None:\n",
    "    benefit1 = purify_cost_share(benefit1)\n",
    "    benefit2 = purify_cost_share(benefit2)    \n",
    "      \n",
    "    benefit1 = benefit1.replace('.', '').replace('$', '').replace('%', '').replace(' ', '').replace(',', '')\n",
    "    benefit2 = benefit2.replace('.', '').replace('$', '').replace('%', '').replace(' ', '').replace(',', '')\n",
    "    return benefit1 == benefit2\n",
    "  return False\n",
    "\n",
    "def get_medicare_site_url(qid):\n",
    "    contractid = qid[:5]\n",
    "    planid = qid[5:8]\n",
    "    segmentid = qid[8:]\n",
    "    return f'https://www.medicare.gov/plan-compare/#/plan-details/{PLAN_YEAR}-{contractid}-{planid}-{int(segmentid)}?year={PLAN_YEAR}&lang=en#benefits'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_inn_oon_costshare(df_benefits):\n",
    "    df_benefits_inn = df_benefits[(df_benefits['INN_CostShare'] != '')]\n",
    "    df_benefits_inn['Network'] = df_benefits_inn.apply(lambda x: 'In-network' if x.pbp_c_pos_yn == 1 or x.pbp_c_oon_yn  == 1 else '', axis=1)\n",
    "    df_benefits_inn = df_benefits_inn[['PlanYear','QID','CategoryName','ServiceName','INN_CostShare','Medicare.gov URL', 'Network']]\n",
    "    df_benefits_inn.rename(columns={\"INN_CostShare\": \"CostShare\"}, inplace=True)\n",
    "    \n",
    "    df_benefits_oon = df_benefits[(df_benefits['OON_CostShare'] != '')]\n",
    "    df_benefits_oon['Network'] = 'Out-of-network'\n",
    "    df_benefits_oon = df_benefits_oon[['PlanYear','QID','CategoryName','ServiceName','OON_CostShare','Medicare.gov URL', 'Network']]\n",
    "    df_benefits_oon.rename(columns={\"OON_CostShare\": \"CostShare\"}, inplace=True)\n",
    "    return pd.concat([df_benefits_inn, df_benefits_oon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajl0618\\AppData\\Local\\Temp\\ipykernel_6456\\1887204967.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_benefits_oon['Network'] = 'Out-of-network'\n"
     ]
    }
   ],
   "source": [
    "# PREVENTIVE DENTAL\tDental X-Rays\n",
    "# Benefit Code = 16b2(NMC)\n",
    "# In-Network & Out-of-Network\n",
    "\n",
    "query = f'''select\n",
    "    a.pbp_a_hnumber as ContractID,\t\n",
    "\ta.pbp_a_plan_identifier as PlanID, \t\n",
    "\ta.segment_id as SegmentID, \n",
    "    pbp_a_special_need_plan_type, pbp_a_dsnp_zerodollar, pbp_a_snp_state_cvg_yn,\n",
    "    pbp_b16b_maxplan_pv_yn,pbp_b16b_maxplan_pv_in_oon,pbp_b16b_maxplan_pv_amt,pbp_b16b_maxplan_pv_per,pbp_b16b_maxplan_pv_per_desc,pbp_b16b_maxenr_pv_yn,pbp_b16b_maxenr_pv_amt,pbp_b16b_maxenr_pv_per,pbp_b16b_maxenr_pv_per_desc,pbp_b16b_coins_ov_yn,pbp_b16b_coins_ov_svcs,pbp_b16b_coins_ov_pct,pbp_b16b_coins_ov_pct_min,pbp_b16b_coins_ov_pct_max,pbp_b16b_copay_ov_yn,pbp_b16b_copay_ov_svcs,pbp_b16b_copay_ov_amt,pbp_b16b_copay_ov_amt_min,pbp_b16b_copay_ov_amt_max,pbp_b16b_ded_pv_yn,pbp_b16b_ded_pv_amt,pbp_b16b_bendesc_oe_amo,pbp_b16b_bendesc_oe_lim,pbp_b16b_bendesc_oe_num,pbp_b16b_bendesc_oe_per,pbp_b16b_bendesc_oe_desc,pbp_b16b_coins_oe_yn,pbp_b16b_coins_oe_pct,pbp_b16b_coins_oe_pct_min,pbp_b16b_coins_oe_pct_max,pbp_b16b_copay_oe_yn,pbp_b16b_copay_oe_amt,pbp_b16b_copay_oe_amt_min,pbp_b16b_copay_oe_amt_max,pbp_b16b_auth_oe_yn,pbp_b16b_refer_oe_yn,pbp_b16b_bendesc_dx_amo,pbp_b16b_bendesc_dx_lim,pbp_b16b_bendesc_dx_num,pbp_b16b_bendesc_dx_per,pbp_b16b_bendesc_dx_desc,pbp_b16b_coins_dx_yn,pbp_b16b_coins_dx_pct,pbp_b16b_coins_dx_pct_min,pbp_b16b_coins_dx_pct_max,pbp_b16b_copay_dx_yn,pbp_b16b_copay_dx_amt,pbp_b16b_copay_dx_amt_min,pbp_b16b_copay_dx_amt_max,pbp_b16b_auth_dx_yn,pbp_b16b_refer_dx_yn,pbp_b16b_bendesc_ods_amo,pbp_b16b_bendesc_ods_lim,pbp_b16b_bendesc_ods_num,pbp_b16b_bendesc_ods_per,pbp_b16b_bendesc_ods_desc,pbp_b16b_coins_ods_yn,pbp_b16b_coins_ods_pct,pbp_b16b_coins_ods_pct_min,pbp_b16b_coins_ods_pct_max,pbp_b16b_copay_ods_yn,pbp_b16b_copay_ods_amt,pbp_b16b_copay_ods_amt_min,pbp_b16b_copay_ods_amt_max,pbp_b16b_auth_ods_yn,pbp_b16b_refer_ods_yn,pbp_b16b_bendesc_pc_amo,pbp_b16b_bendesc_pc_lim,pbp_b16b_bendesc_pc_num,pbp_b16b_bendesc_pc_per,pbp_b16b_bendesc_pc_desc,pbp_b16b_coins_pc_yn,pbp_b16b_coins_pc_pct,pbp_b16b_coins_pc_pct_min,pbp_b16b_coins_pc_pct_max,pbp_b16b_copay_pc_yn,pbp_b16b_copay_pc_amt,pbp_b16b_copay_pc_amt_min,pbp_b16b_copay_pc_amt_max,pbp_b16b_auth_pc_yn,pbp_b16b_refer_pc_yn,pbp_b16b_bendesc_ft_amo,pbp_b16b_bendesc_ft_lim,pbp_b16b_bendesc_ft_num,pbp_b16b_bendesc_ft_per,pbp_b16b_bendesc_ft_desc,pbp_b16b_coins_ft_yn,pbp_b16b_coins_ft_pct,pbp_b16b_coins_ft_pct_min,pbp_b16b_coins_ft_pct_max,pbp_b16b_copay_ft_yn,pbp_b16b_copay_ft_amt,pbp_b16b_copay_ft_amt_min,pbp_b16b_copay_ft_amt_max,pbp_b16b_auth_ft_yn,pbp_b16b_refer_ft_yn,pbp_b16b_bendesc_ops_amo,pbp_b16b_bendesc_ops_lim,pbp_b16b_bendesc_ops_num,pbp_b16b_bendesc_ops_per,pbp_b16b_bendesc_ops_desc,pbp_b16b_coins_ops_yn,pbp_b16b_coins_ops_pct,pbp_b16b_coins_ops_pct_min,pbp_b16b_coins_ops_pct_max,pbp_b16b_copay_ops_yn,pbp_b16b_copay_ops_amt,pbp_b16b_copay_ops_amt_min,pbp_b16b_copay_ops_amt_max,pbp_b16b_auth_ops_yn,pbp_b16b_refer_ops_yn,\n",
    "    c.pbp_c_oon_yn, pbp_c_pos_yn, pbp_c_oon_outpt_maxplan_yn,pbp_c_oon_outpt_maxplan_amt,pbp_c_oon_outpt_maxplan_per,pbp_c_oon_outpt_maxplan_per_d,\n",
    "    pbp_c_oon_outpt_coins_yn,pbp_c_oon_outpt_coins_min_pct,pbp_c_oon_outpt_coins_max_pct,\n",
    "    pbp_c_oon_outpt_copay_yn,pbp_c_oon_outpt_copay_min_amt,pbp_c_oon_outpt_copay_max_amt,\n",
    "    pbp_c_oon_outpt_ded_yn,pbp_c_oon_outpt_ded_amt,\n",
    "    pbp_c_pos_yn, \n",
    "    pbp_c_pos_outpt_coins_yn,pbp_c_pos_outpt_coins_min_pct,pbp_c_pos_outpt_coins_max_pct,\n",
    "    pbp_c_pos_outpt_copay_yn,pbp_c_pos_outpt_copay_min_amt,pbp_c_pos_outpt_copay_max_amt,\n",
    "    pbp_c_pos_outpt_maxplan_yn,pbp_c_pos_outpt_maxplan_amt,pbp_c_pos_outpt_maxplan_per,pbp_c_pos_outpt_maxplan_per_d,pbp_c_pos_outpt_deduct_yn,pbp_c_pos_outpt_deduct_amt\n",
    "from \n",
    "pbp_Section_A a \n",
    "inner join pbp_Section_C c on a.bid_id = c.bid_id\n",
    "inner join pbp_b16_dental b on c.bid_id = b.bid_id\n",
    "left join pbp_Section_C_OON coon on c.bid_id = coon.bid_id and (concat(';', COALESCE(coon.pbp_c_oon_out_mc_bendesc_cats, '')) like '%;16b2;%' or concat(';', COALESCE(coon.pbp_c_oon_out_nmc_bendesc_cats, '')) like '%;16b2;%')\n",
    "left join pbp_Section_C_POS cpos on c.bid_id = cpos.bid_id and (concat(';', COALESCE(cpos.pbp_c_pos_outpt_mc_bencats, '')) like '%;16b2;%' or concat(';', COALESCE(cpos.pbp_c_pos_outpt_nmc_bencats, '')) like '%;16b2;%')\n",
    "where CAST(c.pbp_a_plan_identifier AS INT) < 800 and cast(pbp_a_eghp_yn as int) = 2  \n",
    "and cast(c.PBP_A_PLAN_TYPE as int) in (1, 2, 4, 9, 29, 31, 42, 43, 44, 45 )\n",
    "'''\n",
    "df_b16b_inn = spark.sql(query)\n",
    "write_to_csv_file(df_b16b_inn, 'MedicalBenefits_16b_DataSource')\n",
    "df_medical_benefits_16b2 = read_pd_from_csv_file('MedicalBenefits_16b_DataSource')\n",
    "df_medical_benefits_16b2['PlanYear'] = 2025\n",
    "df_medical_benefits_16b2['QID'] = df_medical_benefits_16b2.apply(lambda x: Plan.get_QID(x), axis=1)\n",
    "df_medical_benefits_16b2['CategoryName'] = 'PREVENTIVE DENTAL'\n",
    "df_medical_benefits_16b2['ServiceName'] = 'Dental X-Rays'\n",
    "\n",
    "from PBP_2025_Benefit_Text import Benefit_16b2\n",
    "df_medical_benefits_16b2['INN_CostShare'] = df_medical_benefits_16b2.apply(lambda x: Benefit_16b2.get_INN_text(x), axis=1)\n",
    "df_medical_benefits_16b2['OON_CostShare'] = df_medical_benefits_16b2.apply(lambda x: Benefit_16b2.get_OON_text(x), axis=1)\n",
    "df_medical_benefits_16b2['Medicare.gov URL'] = df_medical_benefits_16b2.apply(lambda x: get_medicare_site_url(x.QID), axis=1)\n",
    "df_medical_benefits_16b2 = explode_inn_oon_costshare(df_medical_benefits_16b2)\n",
    "df_medical_benefits_16b2 = drop_pbp_mrx_columns(df_medical_benefits_16b2)\n",
    "write_pd_to_csv(df_medical_benefits_16b2,  'MedicalBenefits_16b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate benefit 16b2\n",
    "df_medicare_displaying_benefits.fillna('', inplace=True)\n",
    "df_medical_benefits_16b2.fillna('', inplace=True)\n",
    "df_medicare_displaying_benefits['CostShare'] = df_medicare_displaying_benefits.apply(lambda x: x.CostShare.replace('(always covered)', ''), axis=1)\n",
    "df_medicare_displaying_benefits['CostShare'] = df_medicare_displaying_benefits.apply(lambda x: x.CostShare.replace('(Limits apply)', ''), axis=1)\n",
    "joined_df= pd.merge(df_medical_benefits_16b2, df_medicare_displaying_benefits, how='inner', on=['PlanYear','QID','CategoryName', 'ServiceName', 'Network'])\n",
    "if len(joined_df) > 0:\n",
    "    joined_df['Matched'] = joined_df.apply(lambda x: matched(x.CostShare_x, x.CostShare_y), axis=1)\n",
    "    joined_df.to_csv(DR_TARGET_FOLDER + f'comparison_result_dev.csv', index=False)\n",
    "else:\n",
    "    print('no data file to compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop views from memory if the view exist\n",
    "for t in spark.catalog.listTables():\n",
    "    spark.catalog.dropTempView(t.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
